# Virtualization

-   Allows concurrent execution of multiple OSs and their applications on the same physical device

-   Virtual resources - each OS thinks that it owns hardware resources

-   __Virtual Machine (VM)__ [_guest domain_] - OS + applications + virtual resources

-   __Virtualization layer__ - manages physical hardware [VM monitor/hypervisor]

-   VM: 
    -   efficient, isolated, duplicate of the actual machine
    -   Supported by a __VM monitor (VMM)__
        -   Provides environment essentially identical with original machine [_fidelity_]
        -   Programs show at worst only minor decrease in speed [_performance_]
        -   VMM is in complete control of system resources [_safety & isolation_]

-   Advantages of virtualization:
    -   Consolidation: decrease cost, improve manageability
    -   Migration: availability, reliability
    -   Security, debugging & support for legacy OS
-   Reasons for virtualization not being popular earlier:
    -   Mainframe were not ubiquitous
    -   Other hardware was cheap

-   __Bare Metal Virtualization:__
    -   Hypervisor based
    -   VMM manages all hardware resources & supports execution of VMs
    -   Device manufacturers must provide drivers for hypervisors as well
    -   To eliminate this, hypervisor integrates a special VM, like a service VM with full hardware privileges to deal with devices & run all device drivers. It also runs some configuration & management tasks.
    -   Adopted by Xen & VMware's ESX hypervisor
    -   __Xen__ [open source & Citrix Xen Server]:
        -   VMs are called domains
        -   Privileged domain: `dom0`
        -   Guest VMs: `domUs`
    -   __ESX (VMware):__
        -   Many open APIs
        -   Drivers in the VMM [Due to the largest proportion of market share]
        -   Used to have Linux control core, now remote API

-   __Hosted Virtualization:__
    -   Host owns all hardware
    -   Host OS contains a special VMM module that provides hardware interfaces to VMs & deals with VM context switching
    -   Host OS has device drivers as needed
    -   It can leverage all functionality & mechanisms already developed for the host OS
    -   Native applications can also be run on the Host OS along with guest OSs
    -   Examples:
        -   __KVM (Kernel-based VM)__
            -   Based on Linux
            -   KVM kernel module + __QEMU hardware emulator__ [for hardware virtualization]
            -   Leverages Linux open source community
        -   Others: VirtualBox, Fusion, VMware Player, 

-   Virtualization should protect guest OS from faulty/malicious applications. We should have separate protection levels for apps & guest OSs

-   Virtualization must also protect the VMM from guest OS

-   Hardware Protection Levels:
    -   Commodity hardware has > 2 protection levels
    -   Ex - x86 has 4 protection levels (rings)
        -   Ring 3 - lowest privilege (app)
        -   Ring 0 - highest privilege (OS)
        -   We could have the hypervisor at Ring 0 & OS in Ring 1
    -   Newer x86 have 2 protection modes (root & non-root), each with 4 protection levels:
        -   Non-root: VMs
            -   Ring 3: apps
            -   Ring 0: OS
        -   Root: 
            -   Ring 0: hypervisor [highest privilege level]
        -   Attempts by guest OS to execute privileged operations result in traps called VMexits, which are then handled by hypervisor & it passes control back to guest OS in the form of VMentry

-   __Processor Virtualization:__ Guest instructions - 
    -   Are executed directly by underlying hardware (no VMM involved)
    -   For non-privileged operations run at hardware speed => efficiency
    -   For privileged operations => trap to hypervisor
    -   Hypervisor decides what to do:
        -   If illegal op: terminate VM
        -   If legal op: emulate behaviour that guest OS was expecting from hardware
    -   Problem with Trap-and-Emulate:
        -   Pre 2005, there were no 2 modes yet & some privileged instructions failed silently. So hypervisor did not know something went wrong & continued execution
        -   Access to the privileged register in the form of `PUSHF` & `POPF` failed silently. So guest OS could not request interrupts enabled/disabled & also could not find out the state of interrupts
    -   Solution approaches:
        -   __Binary Translation:__
            -   Rewrite the VM binary to never issue those problematic instructions [used in VMware]
            -   Goal: full virtualization - guest OS not modified
            -   Dynamic binary translation by inspecting the code blocks to be executed
            -   If needed, translate to alternative instruction sequence to emulate desired behavior & avoid the trap, otherwise run at hardware speed
            -   Translation costs can be amortized by caching translated blocks
        -   __Paravirtualization:__
        -   Goal: performance, give up on unmodified guests
        -   Modify guest OS such that:
            -   It knows it is running in a virtualized environment
            -   It makes explicit calls to hypervisor (hypercalls)
        -   Originally popularized by Xen

-   __Memory Virtualization:__
    -   __Full virtualization:__
        -   All guests expect contiguous physical memory starting at 0
        -   Still leverages MMU & TLB
        -   Option 1:
            -   Guest page table: Virtual address => physical address (on guest OS)
            -   Hypervisor: physical address => mchine address (actual address on host OS)
            -   Too expensive
        -   Option 2:
            -   Guest page table: Virtual address => physical address 
            -   __Hypervisor shadow PT:__ VA => machine address
            -   Hypervisor must maintain consistency between 2 PTs
    -   __Paravirtualization:__
        -   Guest aware of virtualization
        -   No longer strict requirement on contiguous physical memory locations starting at 0
        -   Explicitly registers page tables with hypervisor
        -   Can _batch_ page table updates using hypercalls to reduce VMexits

-   For high diversity of devices, there are 3 models for device virtualization:
    -   __Passthrough model__
        -   VMM-level driver configures device access permissions
        -   VM provided with exclusive access to the device
        -   VM directly accesses the device (__VMM bypass__)
        -   Device sharing is difficult
        -   VMM must have exact type of device as what the VM expects
        -   VM migration is tricky
    -   __Hypervisor Direct Model:__
        -   VMM intercepts all device accesses
        -   Emulates device operation:
            -   Translate to generic I/O op
            -   Traverse VMM-resident I/O stack
            -   Invoke VMM-resident driver
        -   VM decoupled from physical device
        -   Sharing & migration is easier
        -   Adds latency on device accesses
        -   Hypervisor must support all device drivers
    -   __Split-Device Driver Model:__
        -   Device access control is split b/w;
            -   __Front-end driver__ in guest VM (device API)
            -   __Back-end driver__ in service VM (or host)
        -   Modified guest drivers, ie limited to paravirtualized guests
        -   Eliminates emulation overheads
        -   Allows better management of shared devices (due to centralised back-end driver)

-   __Hardware Virtualization:__
    -   _Close holes_ in x86 architecture
    -   Allow 2 modes of protection: root/non-root or host/guest
    -   VM control structure - per vCPU
    -   Extended page tables & tagged TLBs with VM ids
    -   __Multiqueue devices__ [devices with multiple logical interfaces for multiple VMs]
    -   Interrupt routing: when device needs to deliver an interrupt to a VM, it actually interrupts the core where the VM is executing & not some other CPU
    -   Security & management support
    -   Additional instructions to exercise the above features